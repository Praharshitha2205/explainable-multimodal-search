## DEMO VIDEO LINK
https://drive.google.com/file/d/1e687Vl3rmt9b50RQ9N-ecyruqCoh370e/view?usp=drivesdk


## Multimodal Knowledge Base Search Engine

## Overview
This project is an explainable multimodal search engine that processes PDF documents, extracts their content, and provides a semantic search capability enhanced by natural language explanations.

Unlike traditional keyword search, it understands the meaning behind queries and documents using AI embeddings, and can generate human-readable synthesized answers referencing the original document context.

## What Was Done Step-by-Step
1. Project Setup and Environment
Created a FastAPI backend server for easy API development and documentation.

Installed necessary Python libraries including fastapi, uvicorn, sentence-transformers, transformers, PyMuPDF (for PDF reading), nltk (for text tokenization), and others.

2. PDF Upload and Content Extraction
Built an API endpoint /upload/ to accept PDF file uploads.

Used the PyMuPDF library to extract both text and images from uploaded PDFs.

Used NLTK to split the extracted text into sentences for granular processing.

3. Semantic Embedding Creation
Leveraged sentence-transformers to convert each extracted sentence into a fixed-size numeric vector (embedding) that captures its semantic meaning.

Stored these embeddings in memory along with the associated text for later search.

4. Semantic Search Endpoint
Created a /search/ endpoint that accepts user queries.

Queries are converted to embeddings with the same model.

Computed cosine similarity between query and stored embeddings to identify top matching sentences.

Returned the most relevant sentences as search results.

5. Answer Synthesis with Local Language Model
Integrated a local language model using Hugging Face's transformers pipeline to generate human-readable answers.

Added a /synthesize/ endpoint that:

Retrieves top matching text chunks for a query.

Passes the chunks and the query into the language model to generate a concise, explainable answer grounded in the document context.

Implemented lazy model loading to prevent slow server startup.

6. Testing and Validation
Used FastAPI's automatically generated Swagger UI to test all endpoints.

Confirmed the ability to upload PDFs, search meaningfully, and get synthesized AI-generated answers.

7. How to Run
Clone the repo and create a Python virtual environment.

8. Install dependencies:

Run the FastAPI server:
i) pip install fastapi
ii) pip install uvicorn
iii) pip install fastapi uvicorn transformers torch sentence-transformers nltk pymupdf pillow numpy
iv) uvicorn knowledge_base_search.main:app --reload --port 8000


Open your browser at http://127.0.0.1:8000/docs to access API docs.

Use /upload/ to upload PDFs.

Use /search/ to perform semantic search queries.

Use /synthesize/ to get explainable answers generated by the local language model.

9. Unique Highlights

Multimodal content extraction including text and images from PDFs.

Semantic search with embeddings instead of keywords.

On-device, API-key-free natural language answer generation.

Lazy loading of heavy models for efficient server startup.

End-to-end functional knowledge base search pipeline.

